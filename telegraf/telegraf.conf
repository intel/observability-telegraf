# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "5s"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  metric_batch_size = 1000

  ## Maximum number of unwritten metrics per output.  Increasing this value
  ## allows for longer periods of output downtime without dropping metrics at the
  ## cost of higher maximum memory usage.
  metric_buffer_limit = 10000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many plugins querying things like sysfs at the
  ## same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  ## Collection offset is used to shift the collection by the given amount.
  ## This can be be used to avoid many plugins querying constraint devices
  ## at the same time by manually scheduling them in time.
  # collection_offset = "0s"

  ## Default flushing interval for all outputs. Maximum flush_interval will be
  ## flush_interval + flush_jitter
  flush_interval = "5s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  ## Collected metrics are rounded to the precision specified. Precision is
  ## specified as an interval with an integer + unit (e.g. 0s, 10ms, 2us, 4s).
  ## Valid time units are "ns", "us" (or "Âµs"), "ms", "s".
  ##
  ## By default or when set to "0s", precision will be set to the same
  ## timestamp order as the collection interval, with the maximum being 1s:
  ##   ie, when interval = "10s", precision will be "1s"
  ##       when interval = "250ms", precision will be "1ms"
  ##
  ## Precision will NOT be used for service inputs. It is up to each individual
  ## service input to set the timestamp at the appropriate precision.
  precision = "0s"

  ## Log at debug level.
  debug = false
  ## Log only error level messages.
  quiet = false

  ## Log target controls the destination for logs and can be one of "file",
  ## "stderr" or, on Windows, "eventlog".  When set to "file", the output file
  ## is determined by the "logfile" setting.
  # logtarget = "file"

  ## Name of the file to be logged to when using the "file" logtarget.  If set to
  ## the empty string then logs are written to stderr.
  logfile = ""

  ## The logfile will be rotated after the time interval specified.  When set
  ## to 0 no time based rotation is performed.  Logs are rotated only when
  ## written to, if there is no log activity rotation may be delayed.
  logfile_rotation_interval = "0h"

  ## The logfile will be rotated when it becomes larger than the specified
  ## size.  When set to 0 no size based rotation is performed.
  # logfile_rotation_max_size = "0MB"

  ## Maximum number of rotated archives to keep, any older logs are deleted.
  ## If set to -1, no archives are removed.
  # logfile_rotation_max_archives = 5

  ## Pick a timezone to use when logging or type 'local' for local time.
  ## Example: America/Chicago
  # log_with_timezone = ""

  ## Override default hostname, if empty use os.Hostname()
  hostname = "$HOSTNAME"
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false

  ## Method of translating SNMP objects. Can be "netsnmp" (deprecated) which
  ## translates by calling external programs snmptranslate and snmptable,
  ## or "gosmi" which translates using the built-in gosmi library.
  # snmp_translator = "netsnmp"

  ## Name of the file to load the state of plugins from and store the state to.
  ## If uncommented and not empty, this file will be used to save the state of
  ## stateful plugins on termination of Telegraf. If the file exists on start,
  ## the state in the file will be restored for the plugins.
  # statefile = ""


###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################


# Send telegraf metrics to file(s)
[[outputs.file]]
  ## Files to write to, "stdout" is a specially handled file.
  files = ["stdout", "/tmp/metrics.out"]

  ## Use batch serialization format instead of line based delimiting.  The
  ## batch format allows for the production of non line based output formats and
  ## may more efficiently encode and write metrics.
  # use_batch_format = false

  ## The file will be rotated after the time interval specified.  When set
  ## to 0 no time based rotation is performed.
  # rotation_interval = "0h"

  ## The logfile will be rotated when it becomes larger than the specified
  ## size.  When set to 0 no size based rotation is performed.
  rotation_max_size = "100MB"

  ## Maximum number of rotated archives to keep, any older logs are deleted.
  ## If set to -1, no archives are removed.
  rotation_max_archives = 5

  ## Data format to output.
  ## Each data format has its own unique set of configuration options, read
  ## more about them here:
  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md
  data_format = "influx"


# Configuration for the Prometheus client to spawn
[[outputs.prometheus_client]]
  ## Address to listen on.
  listen = ":9273"

  ## Maximum duration before timing out read of the request
  # read_timeout = "10s"
  ## Maximum duration before timing out write of the response
  # write_timeout = "10s"

  ## Metric version controls the mapping from Prometheus metrics into Telegraf metrics.
  ## See "Metric Format Configuration" in plugins/inputs/prometheus/README.md for details.
  ## Valid options: 1, 2
  metric_version = 2

  ## Use HTTP Basic Authentication.
  # basic_username = "Foo"
  # basic_password = "Bar"

  ## If set, the IP Ranges which are allowed to access metrics.
  ##   ex: ip_range = ["192.168.0.0/24", "192.168.1.0/30"]
  # ip_range = []

  ## Path to publish the metrics on.
  # path = "/metrics"

  ## Expiration interval for each metric. 0 == no expiration
  # expiration_interval = "60s"

  ## Collectors to enable, valid entries are "gocollector" and "process".
  ## If unset, both are enabled.
  # collectors_exclude = ["gocollector", "process"]

  ## Send string metrics as Prometheus labels.
  ## Unless set to false all string metrics will be sent as labels.
  # string_as_label = true

  ## If set, enable TLS with the given certificate.
  # tls_cert = "/etc/ssl/telegraf.crt"
  # tls_key = "/etc/ssl/telegraf.key"

  ## Set one or more allowed client CA certificate file names to
  ## enable mutually authenticated TLS connections
  # tls_allowed_cacerts = ["/etc/telegraf/clientca.pem"]

  ## Export metric collection time.
  export_timestamp = true


###############################################################################
#                            INPUT PLUGINS                                    #
###############################################################################


# Read specific statistics per cgroup
# This plugin ONLY supports Linux
[[inputs.cgroup]]
  ## Directories in which to look for files, globs are supported.
  ## Consider restricting paths to the set of cgroups you really
  ## want to monitor if you have a large number of cgroups, to avoid
  ## any cardinality issues.
  paths = [
    "/sys/fs/cgroup/cpu",              # root cgroup
    "/sys/fs/cgroup/cpu/*",            # all container cgroups
    "/sys/fs/cgroup/cpu/*/*",          # all children cgroups under each container cgroup
  ]
  ## cgroup stat fields, as file names, globs are supported.
  ## these file names are appended to each path from above.
  files = ["cpuacct.usage", "cpu.cfs_period_us", "cpu.cfs_quota_us", "cpu.shares", "cpu.stat"]


# Read metrics about cpu usage
[[inputs.cpu]]
  ## Whether to report per-cpu stats or not
  percpu = true
  ## Whether to report total system cpu stats or not
  totalcpu = true
  ## If true, collect raw CPU time metrics
  collect_cpu_time = false
  ## If true, compute and report the sum of all non-idle CPU states
  report_active = false
  ## If true and the info is available then add core_id and physical_id tags
  core_tags = true


# Read metrics about disk usage by mount point
[[inputs.disk]]
  ## By default stats will be gathered for all mount points.
  ## Set mount_points will restrict the stats to only the specified mount points.
  # mount_points = ["/"]

  ## Ignore mount points by filesystem type.
  ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]

  ## Ignore mount points by mount options.
  ## The 'mount' command reports options of all mounts in parathesis.
  ## Bind mounts can be ignored with the special 'bind' option.
  # ignore_mount_opts = []


# Read metrics about disk IO by device
[[inputs.diskio]]
  ## By default, telegraf will gather stats for all devices including
  ## disk partitions.
  ## Setting devices will restrict the stats to the specified devices.
  ## NOTE: Globbing expressions (e.g. asterix) are not supported for
  ##       disk synonyms like '/dev/disk/by-id'.
  # devices = ["sda", "sdb", "vd*", "/dev/disk/by-id/nvme-eui.00123deadc0de123"]
  ## Uncomment the following line if you need disk serial numbers.
  # skip_serial_number = false
  #
  ## On systems which support it, device metadata can be added in the form of
  ## tags.
  ## Currently only Linux is supported via udev properties. You can view
  ## available properties for a device by running:
  ## 'udevadm info -q property -n /dev/sda'
  ## Note: Most, but not all, udev properties can be accessed this way. Properties
  ## that are currently inaccessible include DEVTYPE, DEVNAME, and DEVPATH.
  device_tags = ["ID_FS_TYPE", "ID_FS_USAGE"]
  #
  ## Using the same metadata source as device_tags, you can also customize the
  ## name of the device via templates.
  ## The 'name_templates' parameter is a list of templates to try and apply to
  ## the device. The template may contain variables in the form of '$PROPERTY' or
  ## '${PROPERTY}'. The first template which does not contain any variables not
  ## present for the device is used as the device name tag.
  ## The typical use case is for LVM volumes, to get the VG/LV name instead of
  ## the near-meaningless DM-0 name.
  # name_templates = ["$ID_FS_LABEL","$DM_VG_NAME/$DM_LV_NAME"]


# Query given DNS server and gives statistics
[[inputs.dns_query]]
  ## servers to query
  servers = ["8.8.8.8"]

  ## Network is the network protocol name.
  network = "tcp"

  ## Domains or subdomains to query.
  domains = ["google.com"]

  ## Query record type.
  ## Possible values: A, AAAA, CNAME, MX, NS, PTR, TXT, SOA, SPF, SRV.
  # record_type = "A"

  ## Dns server port.
  # port = 53

  ## Query timeout
  # timeout = "2s"

  ## Include the specified additional properties in the resulting metric.
  ## The following values are supported:
  ##    "first_ip" -- return IP of the first A and AAAA answer
  ##    "all_ips"  -- return IPs of all A and AAAA answers
  # include_fields = []


# # Reads metrics from DPDK applications using v2 telemetry interface.
# # This plugin ONLY supports Linux
# [[inputs.dpdk]]
#   ## Path to DPDK telemetry socket. This shall point to v2 version of DPDK
#   ## telemetry interface.
#   # socket_path = "/var/run/dpdk/rte/dpdk_telemetry.v2"
#
#   ## Duration that defines how long the connected socket client will wait for
#   ## a response before terminating connection.
#   ## This includes both writing to and reading from socket. Since it's local
#   ## socket access to a fast packet processing application, the timeout should
#   ## be sufficient for most users.
#   ## Setting the value to 0 disables the timeout (not recommended)
#   # socket_access_timeout = "200ms"
#
#   ## Enables telemetry data collection for selected device types.
#   ## Adding "ethdev" enables collection of telemetry from DPDK NICs
#   ## (stats, xstats, link_status).
#   ## Adding "rawdev" enables collection of telemetry from DPDK Raw Devices
#   ## (xstats).
#   device_types = ["ethdev"]
#
#   ## List of custom, application-specific telemetry commands to query
#   ## The list of available commands depend on the application deployed.
#   ## Applications can register their own commands via telemetry library API
#   ## http://doc.dpdk.org/guides/prog_guide/telemetry_lib.html#registering-commands
#   ## For L3 Forwarding with Power Management Sample Application this could be:
#   ##   additional_commands = ["/l3fwd-power/stats"]
#   # additional_commands = []
#
#   ## Allows turning off collecting data for individual "ethdev" commands.
#   ## Remove "/ethdev/link_status" from list to gather link status metrics.
#   [inputs.dpdk.ethdev]
#     exclude_commands = ["/ethdev/link_status"]
#
#   ## When running multiple instances of the plugin it's recommended to add a
#   ## unique tag to each instance to identify metrics exposed by an instance
#   ## of DPDK application. This is useful when multiple DPDK apps run on a
#   ## single host.
#   ##  [inputs.dpdk.tags]
#   ##    dpdk_instance = "my-fwd-app"


# Returns ethtool statistics for given interfaces
# This plugin ONLY supports Linux
[[inputs.ethtool]]
  ## List of interfaces to pull metrics for
  # interface_include = ["eth0"]

  ## List of interfaces to ignore when pulling metrics.
  # interface_exclude = ["eth1"]

  ## Plugin behavior for downed interfaces
  ## Available choices:
  ##   - expose: collect & report metrics for down interfaces
  ##   - skip: ignore interfaces that are marked down
  # down_interfaces = "expose"

  ## Reading statistics from interfaces in additional namespaces is also
  ## supported, so long as the namespaces are named (have a symlink in
  ## /var/run/netns). The telegraf process will also need the CAP_SYS_ADMIN
  ## permission.
  ## By default, only the current namespace will be used. For additional
  ## namespace support, at least one of `namespace_include` and
  ## `namespace_exclude` must be provided.
  ## To include all namespaces, set `namespace_include` to `["*"]`.
  ## The initial namespace (if anonymous) can be specified with the empty
  ## string ("").

  ## List of namespaces to pull metrics for
  # namespace_include = []

  ## List of namespace to ignore when pulling metrics.
  # namespace_exclude = []

  ## Some drivers declare statistics with extra whitespace, different spacing,
  ## and mix cases. This list, when enabled, can be used to clean the keys.
  ## Here are the current possible normalizations:
  ##  * snakecase: converts fooBarBaz to foo_bar_baz
  ##  * trim: removes leading and trailing whitespace
  ##  * lower: changes all capitalized letters to lowercase
  ##  * underscore: replaces spaces with underscores
  # normalize_keys = ["snakecase", "trim", "lower", "underscore"]


# Gathers huge pages measurements.
# This plugin ONLY supports Linux
[[inputs.hugepages]]
  ## Supported huge page types:
  ##   - "root"     - based on root huge page control directory:
  ##                  /sys/kernel/mm/hugepages
  ##   - "per_node" - based on per NUMA node directories:
  ##                  /sys/devices/system/node/node[0-9]*/hugepages
  ##   - "meminfo"  - based on /proc/meminfo file
  # types = ["root", "per_node"]


# # Intel Baseband Accelerator Input Plugin collects metrics from both dedicated and integrated
# # Intel devices that provide Wireless Baseband hardware acceleration.
# # This plugin ONLY supports Linux.
# [[inputs.intel_baseband]]
#   ## Path to socket exposed by pf-bb-config for CLI interaction (mandatory).
#   ## In version v23.03 of pf-bb-config the path is created according to the schema:
#   ##   "/tmp/pf_bb_config.0000\:<b>\:<d>.<f>.sock" where 0000\:<b>\:<d>.<f> is the PCI device ID.
#   socket_path = ""
#
#   ## Path to log file exposed by pf-bb-config with telemetry to read (mandatory).
#   ## In version v23.03 of pf-bb-config the path is created according to the schema:
#   ##   "/var/log/pf_bb_cfg_0000\:<b>\:<d>.<f>.log" where 0000\:<b>\:<d>.<f> is the PCI device ID.
#   log_file_path = ""
#
#   ## Specifies plugin behavior regarding unreachable socket (which might not have been initialized yet).
#   ## Available choices:
#   ##   - error: Telegraf will return an error on startup if socket is unreachable
#   ##   - ignore: Telegraf will ignore error regarding unreachable socket on both startup and gather
#   # unreachable_socket_behavior = "error"
#
#   ## Duration that defines how long the connected socket client will wait for
#   ## a response before terminating connection.
#   ## Since it's local socket access to a fast packet processing application, the timeout should
#   ## be sufficient for most users.
#   ## Setting the value to 0 disables the timeout (not recommended).
#   # socket_access_timeout = "1s"
#
#   ## Duration that defines maximum time plugin will wait for pf-bb-config to write telemetry to the log file.
#   ## Timeout may differ depending on the environment.
#   ## Must be equal or larger than 50ms.
#   # wait_for_telemetry_timeout = "1s"


# ## Reads metrics from DPDK using v2 telemetry interface.
# ## This plugin ONLY supports Linux
# [[inputs.intel_dlb]]
#   ## Path to DPDK telemetry socket.
#   # socket_path = "/var/run/dpdk/rte/dpdk_telemetry.v2"
#
#   ## Default eventdev command list, it gathers metrics from socket by given commands.
#   ## Supported options:
#   ##   "/eventdev/dev_xstats", "/eventdev/port_xstats",
#   ##   "/eventdev/queue_xstats", "/eventdev/queue_links"
#   # eventdev_commands = ["/eventdev/dev_xstats", "/eventdev/port_xstats", "/eventdev/queue_xstats", "/eventdev/queue_links"]
#
#   ## Detect DLB devices based on device id.
#   ## Currently, only supported and tested device id is `0x2710`.
#   ## Configuration added to support forward compatibility.
#   # dlb_device_types = ["0x2710"]
#
#   ## Specifies plugin behavior regarding unreachable socket (which might not have been initialized yet).
#   ## Available choices:
#   ##   - error: Telegraf will return an error on startup if socket is unreachable
#   ##   - ignore: Telegraf will ignore error regarding unreachable socket on both startup and gather
#   # unreachable_socket_behavior = "error"


# # Intel PowerStat plugin enables monitoring of platform metrics (power, TDP)
# # and per-CPU metrics like temperature, power and utilization.
# # This plugin ONLY supports Linux
# [[inputs.intel_powerstat]]
#   ## The user can choose which package metrics are monitored by the plugin with
#   ## the package_metrics setting:
#   ## - The default, will collect "current_power_consumption",
#   ##   "current_dram_power_consumption" and "thermal_design_power"
#   ## - Leaving this setting empty means no package metrics will be collected
#   ## - Finally, a user can specify individual metrics to capture from the
#   ##   supported options list
#   ## Supported options:
#   ##   "current_power_consumption", "current_dram_power_consumption",
#   ##   "thermal_design_power", "max_turbo_frequency", "uncore_frequency",
#   ##   "cpu_base_frequency"
#   package_metrics = ["current_power_consumption", "current_dram_power_consumption", "thermal_design_power", "max_turbo_frequency", "uncore_frequency", "cpu_base_frequency"]
#
#   ## The user can choose which per-CPU metrics are monitored by the plugin in
#   ## cpu_metrics array.
#   ## Empty or missing array means no per-CPU specific metrics will be collected
#   ## by the plugin.
#   ## Supported options:
#   ##   "cpu_frequency", "cpu_c0_state_residency", "cpu_c1_state_residency",
#   ##   "cpu_c6_state_residency", "cpu_busy_cycles", "cpu_temperature",
#   ##   "cpu_busy_frequency"
#   ## ATTENTION: cpu_busy_cycles is DEPRECATED - use cpu_c0_state_residency
#   cpu_metrics = ["cpu_frequency", "cpu_c0_state_residency", "cpu_c1_state_residency", "cpu_c6_state_residency", "cpu_temperature", "cpu_busy_frequency"]


# # Read metrics from the bare metal servers via IPMI
# [[inputs.ipmi_sensor]]
#   ## optionally specify the path to the ipmitool executable
#   path = "/usr/sbin/ipmitool"
#   ##
#   ## Setting 'use_sudo' to true will make use of sudo to run ipmitool.
#   ## Sudo must be configured to allow the telegraf user to run ipmitool
#   ## without a password.
#   use_sudo = true
#   ##
#   ## optionally force session privilege level. Can be CALLBACK, USER, OPERATOR, ADMINISTRATOR
#   # privilege = "ADMINISTRATOR"
#   ##
#   ## optionally specify one or more servers via a url matching
#   ##  [username[:password]@][protocol[(address)]]
#   ##  e.g.
#   ##    root:passwd@lan(127.0.0.1)
#   ##
#   ## if no servers are specified, local machine sensor stats will be queried
#   ##
#   # servers = ["USERID:PASSW0RD@lan(192.168.1.1)"]
#
#   ## Recommended: use metric 'interval' that is a multiple of 'timeout' to avoid
#   ## gaps or overlap in pulled data
#   interval = "30s"
#
#   ## Timeout for the ipmitool command to complete. Default is 20 seconds.
#   timeout = "20s"
#
#   ## Schema Version: (Optional, defaults to version 1)
#   metric_version = 2
#
#   ## Optionally provide the hex key for the IMPI connection.
#   # hex_key = ""
#
#   ## If ipmitool should use a cache
#   ## for me ipmitool runs about 2 to 10 times faster with cache enabled on HP G10 servers (when using ubuntu20.04)
#   ## the cache file may not work well for you if some sensors come up late
#   # use_cache = false
#
#   ## Path to the ipmitools cache file (defaults to OS temp dir)
#   ## The provided path must exist and must be writable
#   # cache_path = ""


# Gather packets and bytes throughput from iptables
# This plugin ONLY supports Linux
[[inputs.iptables]]
  ## iptables require root access on most systems.
  ## Setting 'use_sudo' to true will make use of sudo to run iptables.
  ## Users must configure sudo to allow telegraf user to run iptables with
  ## no password.
  ## iptables can be restricted to only list command "iptables -nvL".
  use_sudo = true
  ## Setting 'use_lock' to true runs iptables with the "-w" option.
  ## Adjust your sudo settings appropriately if using this option
  ## ("iptables -w 5 -nvl")
  use_lock = false
  ## Define an alternate executable, such as "ip6tables". Default is "iptables".
  # binary = "iptables-ntf"
  ## defines the table to monitor:
  table = "filter"
  ## defines the chains to monitor.
  ## NOTE: iptables rules without a comment will not be monitored.
  ## Read the plugin documentation for more information.
  chains = [ "INPUT" ]


# Get kernel statistics from /proc/vmstat
# This plugin ONLY supports Linux
[[inputs.kernel_vmstat]]
  # no configuration


# # The libvirt plugin collects statistics from virtualized guests using virtualization libvirt API.
# [[inputs.libvirt]]
#      ## Domain names from which libvirt gather statistics.
#      ## By default (empty or missing array) the plugin gather statistics from each domain registered in the host system.
#      # domains = []
#
#      ## Libvirt connection URI with hypervisor.
#      ## The plugin supports multiple transport protocols and approaches which are configurable via the URI.
#      ## The general URI form: driver[+transport]://[username@][hostname][:port]/[path][?extraparameters]
#      ## Supported transport protocols: ssh, tcp, tls, unix
#      ## URI examples for each type of transport protocol:
#      ## 1. SSH:  qemu+ssh://<USER@IP_OR_HOSTNAME>/system?keyfile=/<PATH_TO_PRIVATE_KEY>&known_hosts=/<PATH_TO_known_hosts>
#      ## 2. TCP:  qemu+tcp://<IP_OR_HOSTNAME>/system
#      ## 3. TLS:  qemu+tls://<HOSTNAME>/system?pkipath=/certs_dir/<COMMON_LOCATION_OF_CACERT_AND_SERVER_CLIENT_CERTS>
#      ## 4. UNIX: qemu+unix:///system?socket=/<PATH_TO_libvirt-sock>
#      ## Default URI is qemu:///system
#      # libvirt_uri = "qemu:///system"
#
#      ## Statistics groups for which libvirt plugin will gather statistics.
#      ## Supported statistics groups: state, cpu_total, balloon, vcpu, interface, block, perf, iothread, memory, dirtyrate
#      ## Empty array means no metrics for statistics groups will be exposed by the plugin.
#      ## By default the plugin will gather all available statistics.
#      # statistics_groups = ["state", "cpu_total", "balloon", "vcpu", "interface", "block", "perf", "iothread", "memory", "dirtyrate"]
#
#      ## A list containing additional statistics to be exposed by libvirt plugin.
#      ## Supported additional statistics: vcpu_mapping
#      ## By default (empty or missing array) the plugin will not collect additional statistics.
#      # additional_statistics = []



# Read metrics about memory usage
[[inputs.mem]]
  # no configuration


# Gather metrics about network interfaces
[[inputs.net]]
  ## By default, telegraf gathers stats from any up interface (excluding loopback)
  ## Setting interfaces will tell it to gather these explicit interfaces,
  ## regardless of status. When specifying an interface, glob-style
  ## patterns are also supported.
  ##
  # interfaces = ["eth*", "enp0s[0-1]", "lo"]
  ##
  ## On linux systems telegraf also collects protocol stats.
  ## Setting ignore_protocol_stats to true will skip reporting of protocol metrics.
  ##
  ## DEPRECATION NOTICE: A value of 'false' is deprecated and discouraged!
  ##                     Please set this to `true` and use the 'inputs.nstat'
  ##                     plugin instead.
  # ignore_protocol_stats = false


# # P4Runtime telemetry input plugin
# [[inputs.p4runtime]]
#   ## Define the endpoint of P4Runtime gRPC server to collect metrics.
#   # endpoint = "127.0.0.1:9559"
#   ## Set DeviceID required for Client Arbitration.
#   ## https://p4.org/p4-spec/p4runtime/main/P4Runtime-Spec.html#sec-client-arbitration-and-controller-replication
#   # device_id = 1
#   ## Filter counters by their names that should be observed.
#   ## Example: counter_names_include=["ingressCounter", "egressCounter"]
#   # counter_names_include = []
#
#   ## Optional TLS Config.
#   ## Enable client-side TLS and define CA to authenticate the device.
#   # enable_tls = false
#   # tls_ca = "/etc/telegraf/ca.crt"
#   ## Set minimal TLS version to accept by the client.
#   # tls_min_version = "TLS12"
#   ## Use TLS but skip chain & host verification.
#   # insecure_skip_verify = true
#
#   ## Define client-side TLS certificate & key to authenticate to the device.
#   # tls_cert = "/etc/telegraf/client.crt"
#   # tls_key = "/etc/telegraf/client.key"


# Ping given url(s) and return statistics
[[inputs.ping]]
  ## Hosts to send ping packets to.
  urls = ["google.com"]

  ## Method used for sending pings, can be either "exec" or "native".  When set
  ## to "exec" the systems ping command will be executed.  When set to "native"
  ## the plugin will send pings directly.
  ##
  ## While the default is "exec" for backwards compatibility, new deployments
  ## are encouraged to use the "native" method for improved compatibility and
  ## performance.
  # method = "exec"

  ## Number of ping packets to send per interval.  Corresponds to the "-c"
  ## option of the ping command.
  # count = 1

  ## Time to wait between sending ping packets in seconds.  Operates like the
  ## "-i" option of the ping command.
  # ping_interval = 1.0

  ## If set, the time to wait for a ping response in seconds.  Operates like
  ## the "-W" option of the ping command.
  # timeout = 1.0

  ## If set, the total ping deadline, in seconds.  Operates like the -w option
  ## of the ping command.
  # deadline = 10

  ## Interface or source address to send ping from.  Operates like the -I or -S
  ## option of the ping command.
  # interface = ""

  ## Percentiles to calculate. This only works with the native method.
  # percentiles = [50, 95, 99]

  ## Specify the ping executable binary.
  # binary = "ping"

  ## Arguments for ping command. When arguments is not empty, the command from
  ## the binary option will be used and other options (ping_interval, timeout,
  ## etc) will be ignored.
  # arguments = ["-c", "3"]

  ## Use only IPv6 addresses when resolving a hostname.
  # ipv6 = false

  ## Number of data bytes to be sent. Corresponds to the "-s"
  ## option of the ping command. This only works with the native method.
  # size = 56


# # Read CPU, Fans, Powersupply and Voltage metrics of hardware server through redfish APIs
# [[inputs.redfish]]
#   ## Redfish API Base URL.
#   address = "http://localhost:8000/redfish/v1"
#
#   ## Credentials for the Redfish API.
#   username = "root"
#   password = "password123456"
#
#   ## System Id to collect data for in Redfish APIs.
#   computer_system_id="1"
#
#   ## Amount of time allowed to complete the HTTP request
#   # timeout = "5s"
#
#   ## Optional TLS Config
#   # tls_ca = "/etc/telegraf/ca.pem"
#   # tls_cert = "/etc/telegraf/cert.pem"
#   # tls_key = "/etc/telegraf/key.pem"
#   ## Use TLS but skip chain & host verification
#   # insecure_skip_verify = false


# Read metrics from storage devices supporting S.M.A.R.T.
[[inputs.smart]]
    ## Optionally specify the path to the smartctl executable
    path_smartctl = "/usr/sbin/smartctl"

    ## Optionally specify the path to the nvme-cli executable
    path_nvme = "/usr/sbin/nvme"

    ## Optionally specify if vendor specific attributes should be propagated for NVMe disk case
    ## ["auto-on"] - automatically find and enable additional vendor specific disk info
    ## ["vendor1", "vendor2", ...] - e.g. "Intel" enable additional Intel specific disk info
    # enable_extensions = ["auto-on"]

    ## On most platforms used cli utilities requires root access.
    ## Setting 'use_sudo' to true will make use of sudo to run smartctl or nvme-cli.
    ## Sudo must be configured to allow the telegraf user to run smartctl or nvme-cli
    ## without a password.
    use_sudo = true

    ## Skip checking disks in this power mode. Defaults to
    ## "standby" to not wake up disks that have stopped rotating.
    ## See --nocheck in the man pages for smartctl.
    ## smartctl version 5.41 and 5.42 have faulty detection of
    ## power mode and might require changing this value to
    ## "never" depending on your disks.
    # nocheck = "standby"

    ## Gather all returned S.M.A.R.T. attribute metrics and the detailed
    ## information from each drive into the 'smart_attribute' measurement.
    attributes = true

    ## Optionally specify devices to exclude from reporting if disks auto-discovery is performed.
    # excludes = [ "/dev/pass6" ]

    ## Optionally specify devices and device type, if unset
    ## a scan (smartctl --scan and smartctl --scan -d nvme) for S.M.A.R.T. devices will be done
    ## and all found will be included except for the excluded in excludes.
    # devices = [ "/dev/ada0 -d atacam", "/dev/nvme0"]

    ## Timeout for the cli command to complete.
    # timeout = "30s"

    ## Optionally call smartctl and nvme-cli with a specific concurrency policy.
    ## By default, smartctl and nvme-cli are called in separate threads (goroutines) to gather disk attributes.
    ## Some devices (e.g. disks in RAID arrays) may have access limitations that require sequential reading of
    ## SMART data - one individual array drive at the time. In such case please set this configuration option
    ## to "sequential" to get readings for all drives.
    ## valid options: concurrent, sequential
    # read_method = "concurrent"


# Read metrics about system load & uptime
[[inputs.system]]
  # no configuration


# Read metrics about temperature
[[inputs.temp]]
  # no configuration


###############################################################################
#                            SERVICE INPUT PLUGINS                            #
###############################################################################


# # Intel Performance Monitoring Unit plugin exposes Intel PMU metrics available through Linux Perf subsystem
# # This plugin ONLY supports Linux on amd64
# [[inputs.intel_pmu]]
#   ## List of filesystem locations of JSON files that contain PMU event definitions.
#   event_definitions = ["/var/cache/pmu/GenuineIntel-6-55-4-core.json", "/var/cache/pmu/GenuineIntel-6-55-4-uncore.json"]
#
#   ## List of core events measurement entities. There can be more than one core_events sections.
#   [[inputs.intel_pmu.core_events]]
#     ## List of events to be counted. Event names shall match names from event_definitions files.
#     ## Single entry can contain name of the event (case insensitive) augmented with config options and perf modifiers.
#     ## If absent, all core events from provided event_definitions are counted skipping unresolvable ones.
#     events = ["INST_RETIRED.ANY", "CPU_CLK_UNHALTED.THREAD_ANY:config1=0x4043200000000k"]
#
#     ## Limits the counting of events to core numbers specified.
#     ## If absent, events are counted on all cores.
#     ## Single "0", multiple "0,1,2" and range "0-2" notation is supported for each array element.
#     ##   example: cores = ["0,2", "4", "12-16"]
#     cores = ["0"]
#
#     ## Indicator that plugin shall attempt to run core_events.events as a single perf group.
#     ## If absent or set to false, each event is counted individually. Defaults to false.
#     ## This limits the number of events that can be measured to a maximum of available hardware counters per core.
#     ## Could vary depending on type of event, use of fixed counters.
#     # perf_group = false
#
#     ## Optionally set a custom tag value that will be added to every measurement within this events group.
#     ## Can be applied to any group of events, unrelated to perf_group setting.
#     # events_tag = ""
#
#   ## List of uncore event measurement entities. There can be more than one uncore_events sections.
#   [[inputs.intel_pmu.uncore_events]]
#     ## List of events to be counted. Event names shall match names from event_definitions files.
#     ## Single entry can contain name of the event (case insensitive) augmented with config options and perf modifiers.
#     ## If absent, all uncore events from provided event_definitions are counted skipping unresolvable ones.
#     events = ["UNC_CHA_CLOCKTICKS", "UNC_CHA_TOR_OCCUPANCY.IA_MISS"]
#
#     ## Limits the counting of events to specified sockets.
#     ## If absent, events are counted on all sockets.
#     ## Single "0", multiple "0,1" and range "0-1" notation is supported for each array element.
#     ##   example: sockets = ["0-2"]
#     sockets = ["0"]
#
#     ## Indicator that plugin shall provide an aggregated value for multiple units of same type distributed in an uncore.
#     ## If absent or set to false, events for each unit are exposed as separate metric. Defaults to false.
#     # aggregate_uncore_units = false
#
#     ## Optionally set a custom tag value that will be added to every measurement within this events group.
#     # events_tag = ""


# # Read Intel RDT metrics
# # This plugin ONLY supports non-Windows
# [[inputs.intel_rdt]]
#   ## Optionally set sampling interval to Nx100ms.
#   ## This value is propagated to pqos tool. Interval format is defined by pqos itself.
#   ## If not provided or provided 0, will be set to 10 = 10x100ms = 1s.
#   # sampling_interval = "10"
#
#   ## Optionally specify the path to pqos executable.
#   ## If not provided, auto discovery will be performed.
#   # pqos_path = "/usr/local/bin/pqos"
#
#   ## Optionally specify if IPC and LLC_Misses metrics shouldn't be propagated.
#   ## If not provided, default value is false.
#   # shortened_metrics = false
#
#   ## Specify the list of groups of CPU core(s) to be provided as pqos input.
#   ## Mandatory if processes aren't set and forbidden if processes are specified.
#   ## e.g. ["0-3", "4,5,6"] or ["1-3,4"]
#   cores = ["0-3"]
#
#   ## Specify the list of processes for which Metrics will be collected.
#   ## Mandatory if cores aren't set and forbidden if cores are specified.
#   ## e.g. ["qemu", "pmd"]
#   # processes = ["process"]
#
#   ## Specify if the pqos process should be called with sudo.
#   ## Mandatory if the telegraf process does not run as root.
#   use_sudo = true


# # RAS plugin exposes counter metrics for Machine Check Errors provided by RASDaemon (sqlite3 output is required).
# # This plugin ONLY supports Linux on 386, amd64, arm, and arm64
# [[inputs.ras]]
#   ## Optional path to RASDaemon sqlite3 database.
#   ## Default: /var/lib/rasdaemon/ras-mc_event.db
#   # db_path = ""

